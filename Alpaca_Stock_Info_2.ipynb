{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Initial imports\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import alpaca_trade_api as tradeapi\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Load the environment variables by calling the load_dotenv function\n",
    "load_dotenv()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Set Alpaca API key and secret by calling the os.getenv function and referencing the environment variable names\n",
    "# Set each environment variable to a notebook variable of the same name\n",
    "alpaca_api_key = os.getenv(\"ALPACA_API_KEY\")\n",
    "alpaca_secret_key = os.getenv(\"ALPACA_SECRET_KEY\")\n",
    "\n",
    "# Check the values were imported correctly by evaluating the type of each\n",
    "display(type(alpaca_api_key))\n",
    "display(type(alpaca_secret_key))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create your Alpaca API REST object by calling Alpaca's tradeapi.REST function\n",
    "# Set the parameters to your alpaca_api_key, alpaca_secret_key and api_version=\"v2\"\n",
    "alpaca = tradeapi.REST(\n",
    "    alpaca_api_key,\n",
    "    alpaca_secret_key,\n",
    "    api_version=\"v2\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Format the current date as ISO format\n",
    "today = pd.Timestamp(\"2021-09-28\", tz=\"America/New_York\").isoformat()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Set the tickers for the stocks you have chosen\n",
    "# We are selecting the following 15 (note to group that 14 currently work, but added in VOO)\n",
    "tickers = [\"TSM\", \"QCOM\", \"VALE\", \"AMD\", \"BHP\", \"RIO\", \"FCX\", \"INTC\", \"MSFT\", \"DDD\", \"NVDA\", \"TSLA\", \"AMAT\", \"F\", \"VOO\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Set timeframe to one day ('1D') for the Alpaca API\n",
    "timeframe = \"1D\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Get current closing prices for above stocks\n",
    "df_portfolio = alpaca.get_barset(\n",
    "    tickers,\n",
    "    timeframe,\n",
    "    start = today,\n",
    "    end = today,\n",
    "    limit = 500\n",
    ").df\n",
    "\n",
    "# Display sample data\n",
    "# Auto formats in alphabetical order\n",
    "df_portfolio"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# The farthest Alpaca will go back is 4 months for one pull\n",
    "# Format start and end dates as ISO format for one year period\n",
    "start = pd.Timestamp(\"2021-05-28\", tz=\"America/New_York\").isoformat()\n",
    "end = pd.Timestamp(\"2021-09-28\", tz=\"America/New_York\").isoformat()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Get closing prices for chosen stocks from start to end date of choice\n",
    "df_portfolio_months = alpaca.get_barset(\n",
    "    tickers,\n",
    "    timeframe,\n",
    "    start = start,\n",
    "    end = end,\n",
    "    limit = 1000\n",
    ").df\n",
    "\n",
    "# Display sample data\n",
    "df_portfolio_months.head(10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Clean the data and drop all columns except for closing\n",
    "df_portfolio_months_clean = df_portfolio_months.drop(['open', 'low', 'high'], axis=1, level=1)\n",
    "\n",
    "# Display sample data\n",
    "df_portfolio_months_clean.head(10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# The farthest Alpaca will go back is 4 months for one pull, so we repeat process below\n",
    "# Format start and end dates as ISO format for four month period\n",
    "# Use the start date above as the end date below\n",
    "start_2 = pd.Timestamp(\"2021-01-01\", tz=\"America/New_York\").isoformat()\n",
    "end_2 = pd.Timestamp(\"2021-05-27\", tz=\"America/New_York\").isoformat()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Get closing prices for chosen stocks from start to end date of choice\n",
    "df_portfolio_months_2 = alpaca.get_barset(\n",
    "    tickers,\n",
    "    timeframe,\n",
    "    start = start_2,\n",
    "    end = end_2,\n",
    "    limit = 1000\n",
    ").df\n",
    "\n",
    "# Clean the data and drop all columns except for closing\n",
    "df_portfolio_months_2_clean = df_portfolio_months_2.drop(['open', 'low', 'high'], axis=1, level=1)\n",
    "\n",
    "# Display sample data\n",
    "df_portfolio_months_2_clean.head(10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# The farthest Alpaca will go back is 4 months for one pull, so we repeat process below\n",
    "# Format start and end dates as ISO format for four month period\n",
    "# Use the start date above as the end date below\n",
    "\n",
    "start_3 = pd.Timestamp(\"2020-09-28\", tz=\"America/New_York\").isoformat()\n",
    "end_3 = pd.Timestamp(\"2021-01-01\", tz=\"America/New_York\").isoformat()\n",
    "\n",
    "df_portfolio_months_3 = alpaca.get_barset(\n",
    "    tickers,\n",
    "    timeframe,\n",
    "    start = start_3,\n",
    "    end = end_3,\n",
    "    limit = 1000\n",
    ").df\n",
    "\n",
    "# Clean the data and drop all columns except for closing\n",
    "df_portfolio_months_3_clean = df_portfolio_months_3.drop(['open', 'low', 'high'], axis=1, level=1)\n",
    "\n",
    "# Display sample data\n",
    "df_portfolio_months_3_clean.head(10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Combine all the cleaned data into one table by using concat\n",
    "merged_portfolio = pd.concat([df_portfolio_months_3_clean, df_portfolio_months_2_clean, df_portfolio_months_clean])\n",
    "\n",
    "# Display the head and tail of the newly merged portfolio\n",
    "display(merged_portfolio.head())\n",
    "display(merged_portfolio.tail())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Assign save path to variable\n",
    "save_path = Path('./cleaned_stock_data.csv')\n",
    "\n",
    "# Send to CSV file if file does not already exist\n",
    "if not save_path.is_file():\n",
    "    merged_portfolio.to_csv(save_path)\n",
    "else:\n",
    "    # alright, proceed...\n",
    "    print('csv output not resaved.')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Graph your stocks closing prices over the course of the last year by using the data you just merged into one portfolio\n",
    "# We are graphing the data to get a visualization over the stock closing price performance over the last year\n",
    "\n",
    "# First remove the volume column from the portfolio to just plot the closing prices\n",
    "merged_portfolio_close_dates = merged_portfolio.drop(['volume'], axis=1, level=1)\n",
    "\n",
    "merged_portfolio_close_dates.plot()\n",
    "plt.title('Full Calendar Year of Closing Prices for Chosen Stocks')\n",
    "plt.ylabel('Closing Prices')\n",
    "plt.xlabel('Date')\n",
    "plt.legend(loc=\"lower right\", bbox_to_anchor=(1.4, -0.19), ncol=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Graph your stocks daily volume over the course of the last year by using the data you just merged into one portfolio\n",
    "# We are graphing the data to get a visualization over the changes in volume over the last year\n",
    "\n",
    "# First remove the close column from the portfolio to just plot the volume\n",
    "merged_portfolio_volumes = merged_portfolio.drop(['close'], axis=1, level=1)\n",
    "\n",
    "merged_portfolio_volumes.plot()\n",
    "plt.title('Full Calendar Year of Volume for Chosen Stocks')\n",
    "plt.ylabel('Volume')\n",
    "plt.xlabel('Date')\n",
    "plt.legend(loc=\"lower right\", bbox_to_anchor=(1.4, -0.19), ncol=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a Lagged Volume column that shifts the volume of each stock back by one day\n",
    "\n",
    "# Since there are multiple columns with the name volume, we must create a loop \n",
    "for widget in merged_portfolio.columns.levels[0]:\n",
    "    merged_portfolio.loc[:,(widget, 'lagged volume')] = merged_portfolio[(widget, 'volume')].shift(1)\n",
    "\n",
    "# Then we sort the columns to show within each stock\n",
    "merged_portfolio = merged_portfolio.sort_index(axis=1, level=0)\n",
    "\n",
    "#Drop NA values\n",
    "merged_portfolio.dropna(inplace=True)\n",
    "\n",
    "#Display portfolio \n",
    "merged_portfolio.head(10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a Daily Stock Return column that will calculate the daily percent change of the closing stock prices\n",
    "\n",
    "# Since there are multiple columns with the name close, we must create a loop \n",
    "\n",
    "for stock in merged_portfolio.columns.levels[0]:\n",
    "    merged_portfolio.loc[:,(stock, 'daily return')] = merged_portfolio[(stock, 'close')].pct_change()\n",
    "\n",
    "# Then we sort the columns to show within each stock\n",
    "merged_portfolio = merged_portfolio.sort_index(axis=1, level=0)\n",
    "\n",
    "#Display first and last five rows of the portfolio \n",
    "display(merged_portfolio.head())\n",
    "display(merged_portfolio.tail())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a Stock Volatility column that will calculate the standard deviation of the closing stock prices\n",
    "\n",
    "# Since there are multiple columns with the name close, we must create a loop \n",
    "\n",
    "for volatility in merged_portfolio.columns.levels[0]:\n",
    "    merged_portfolio.loc[:,(volatility, 'stock volatility')] = merged_portfolio[(volatility, 'close')].pct_change().rolling(window=200).std()\n",
    "\n",
    "# Then we sort the columns to show within each stock\n",
    "merged_portfolio = merged_portfolio.sort_index(axis=1, level=0)\n",
    "\n",
    "#Display portfolio \n",
    "merged_portfolio.tail(10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Graph your stock volatility over the course of the last year by using the data you calculated above\n",
    "# We are graphing the data to get a visualization over the stock volatility over the last year\n",
    "\n",
    "# First remove the close, volume, lagged volume, and daily return columns from the portfolio to just plot the volume\n",
    "\n",
    "merged_portfolio_stock_volatility = merged_portfolio.drop(['close', 'volume', 'lagged volume', 'daily return'], axis=1, level=1)\n",
    "\n",
    "merged_portfolio_stock_volatility.plot()\n",
    "plt.title('Stock Volatility for Chosen Stocks')\n",
    "plt.ylabel('Volatility')\n",
    "plt.xlabel('Date')\n",
    "plt.legend(loc=\"lower right\", bbox_to_anchor=(1.53, -0.19), ncol=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Creating a correlation table of the daily stock return, lagged volume, and stock volatility\n",
    "\n",
    "merged_portfolio_corr = merged_portfolio.drop(['close', 'volume'], axis=1, level=1)\n",
    "\n",
    "merged_portfolio_corr.corr()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Original idea to calculate correlation \n",
    "\n",
    "# merged_portfolio_TSM_corr = merged_portfolio.drop([\"QCOM\", \"VALE\", \"AMD\", \"BHP\", \"RIO\", \"FCX\", \"INTC\", \"MSFT\", \"DDD\", \"NVDA\", \"TSLA\", \"AMAT\", \"F\", \"VOO\"], axis=1, level=0)\n",
    "\n",
    "# merged_portfolio_TSM_corr.corr()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Below we start running Bollinger Bands to determine return percentage"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "merged_portfolio_daily_returns = merged_portfolio.drop(['close', 'volume', 'lagged volume', 'stock volatility'], axis=1, level=1)\n",
    "\n",
    "merged_portfolio_daily_returns.dropna(inplace=True)\n",
    "\n",
    "merged_portfolio_daily_returns.head(10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Original strategy to get the covariance of each stock in portfolio\n",
    "\n",
    "# Below calculates the covariance of TSM to the VOO\n",
    "\n",
    "merged_portfolio_TSM_cov = merged_portfolio_daily_returns['TSM']['daily return'].cov(merged_portfolio_daily_returns['VOO']['daily return'])\n",
    "\n",
    "merged_portfolio_TSM_cov\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Creating a loop to get all the stock covariances to the VOO at once in the order below\n",
    "\n",
    "stock_ticker_list = [\"TSM\", \"QCOM\", \"VALE\", \"AMD\", \"BHP\", \"RIO\", \"FCX\", \"INTC\", \"MSFT\", \"DDD\", \"NVDA\", \"TSLA\", \"AMAT\", \"F\"]\n",
    "\n",
    "stock_covariance_list = []\n",
    "\n",
    "for stock in stock_ticker_list:\n",
    "    stockcov = merged_portfolio_daily_returns[stock]['daily return'].cov(merged_portfolio_daily_returns['VOO']['daily return'])\n",
    "    stock_covariance_list+=[stockcov]\n",
    "\n",
    "print(stock_covariance_list)\n",
    "   "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create the variance calculation of all the daily returns vs. VOO\n",
    "\n",
    "VOO_variance = merged_portfolio_daily_returns['VOO']['daily return'].var()\n",
    "\n",
    "print(VOO_variance)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# trying to create a loop that divided the covariance of each stock by the variance of VOO, both of which have been calculated above already\n",
    "\n",
    "stock_beta_list = []\n",
    "\n",
    "for covariance in stock_covariance_list:\n",
    "    stockbeta = covariance / VOO_variance\n",
    "    stock_beta_list += [stockbeta]\n",
    "\n",
    "print(stock_beta_list)\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Remove VOO from the stock_beta_list\n",
    "# Assign the VOO beta to a variable\n",
    "voo_beta = stock_beta_list.pop()\n",
    "\n",
    "# Print the beta of VOO\n",
    "print(voo_beta)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Assign the stock_beta_list without voo to stock_beta_list_wo_voo\n",
    "stock_beta_list_wo_voo = stock_beta_list\n",
    "\n",
    "# Print stock_beta_list_wo_voo\n",
    "print(stock_beta_list_wo_voo)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# If we used even weights for all stocks in the portfolio\n",
    "# The portfolio beta would be the sum of the betas for all the stocks over the number of stocks in the portfolio\n",
    "# Calculating the portfolio beta\n",
    "stock_beta_list_wo_voo_sum = sum(stock_beta_list_wo_voo)\n",
    "stock_beta_list_wo_voo_count = len(stock_beta_list_wo_voo)\n",
    "stock_beta_list_wo_voo_beta = stock_beta_list_wo_voo_sum / stock_beta_list_wo_voo_count\n",
    "\n",
    "# Print the portfolio beta given even weights for all stocks\n",
    "print(stock_beta_list_wo_voo_beta)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a new DataFrame trading_df using the merged_portfolio DataFrame\n",
    "trading_df = merged_portfolio\n",
    "\n",
    "# Display the first five rows of the DataFrame\n",
    "trading_df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Display Column headers for the trading_df\n",
    "display(list(trading_df.columns.values))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Drop VOO from the trading_df DataFRame\n",
    "trading_df = trading_df.drop(['VOO'], axis=1)\n",
    "\n",
    "# View the Updated DataFrame Columns\n",
    "display(list(trading_df.columns.values))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# View the Updated DataFrame\n",
    "display(trading_df.head())\n",
    "display(trading_df.tail())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Define a window size of 4\n",
    "short_window = 4\n",
    "\n",
    "# Define a window size of 100\n",
    "long_window = 100\n",
    "\n",
    "# Re-define stock_ticker_list to ensure integrity\n",
    "stock_ticker_list = [\"AMAT\", \"AMD\", \"BHP\", \"DDD\", \"F\", \"FCX\", \"INTC\", \"MSFT\", \"NVDA\", \"QCOM\", \"RIO\", \"TSLA\", \"TSM\", \"VALE\"]\n",
    "\n",
    "# Loop through the trading_df to create the sma_fast and sma_slow columns \n",
    "for stock in stock_ticker_list:\n",
    "    # Create an SMA that uses short_window, and assign it to a new column named “sma_fast”\n",
    "    trading_df.loc[:,(stock, 'sma_fast')] = trading_df[(stock, 'close')].rolling(window=short_window).mean()\n",
    "    # Create an SMA that uses long_window, and assign it to a new column named “sma_slow”\n",
    "    trading_df.loc[:,(stock, 'sma_slow')] = trading_df[(stock, 'close')].rolling(window=long_window).mean()\n",
    "    \n",
    "# Then we sort the columns to show within each stock\n",
    "trading_df = trading_df.sort_index(axis=1, level=0)\n",
    "    \n",
    "# Display the first and last five rows of the trading_df\n",
    "display(trading_df.head())\n",
    "display(trading_df.tail())\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Drop the NaNs using dropna()\n",
    "trading_df.dropna(axis=0, inplace=True)\n",
    "\n",
    "# Display the first and last five rows\n",
    "display(trading_df.head())\n",
    "display(trading_df.tail())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create X DataFrame\n",
    "X = pd.DataFrame(columns = trading_df.columns)\n",
    "\n",
    "# Re-define stock_ticker_list to ensure integrity\n",
    "stock_ticker_list = [\"AMAT\", \"AMD\", \"BHP\", \"DDD\", \"F\", \"FCX\", \"INTC\", \"MSFT\", \"NVDA\", \"QCOM\", \"RIO\", \"TSLA\", \"TSM\", \"VALE\"]\n",
    "\n",
    "# Assign a copy of the `sma_fast` and `sma_slow` columns to the new DataFrame called `X`\n",
    "# Loop through the trading_df\n",
    "for stock in stock_ticker_list:\n",
    "    X.loc[:,(stock, 'sma_fast')] = trading_df[(stock, 'sma_fast')].shift().dropna().copy()\n",
    "    X.loc[:,(stock, 'sma_slow')] = trading_df[(stock, 'sma_slow')].shift().dropna().copy()\n",
    "\n",
    "# Drop columns other than sma_fast and sma_slow\n",
    "X = X.drop(['close', 'daily return', 'lagged volume', 'stock volatility', 'volume'], axis='columns', level=1)\n",
    "\n",
    "# Display the first and last five rows of the X DataFrame\n",
    "display(X.head())\n",
    "display(X.tail())\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Re-define stock_ticker_list to ensure integrity\n",
    "stock_ticker_list = [\"AMAT\", \"AMD\", \"BHP\", \"DDD\", \"F\", \"FCX\", \"INTC\", \"MSFT\", \"NVDA\", \"QCOM\", \"RIO\", \"TSLA\", \"TSM\", \"VALE\"]\n",
    "\n",
    "# Create a new column in the `trading_df` called \"signal\" setting its value to zero.\n",
    "# Loop through the trading_df to create the signal column\n",
    "for stock in stock_ticker_list:\n",
    "    trading_df.loc[:,(stock, 'signal')] = 0.0\n",
    "\n",
    "# Then we sort the columns to show within each stock\n",
    "trading_df = trading_df.sort_index(axis=1, level=0)\n",
    "\n",
    "# Review the trading_df\n",
    "# Display the first and last five rows\n",
    "display(trading_df.head())\n",
    "display(trading_df.tail())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Set signal values\n",
    "for stock in stock_ticker_list:\n",
    "    # Create the signal to buy\n",
    "    trading_df.loc[(trading_df[stock]['daily return'] >= 0), (stock, 'signal')] = 1\n",
    "    # Create the signal to sell\n",
    "    trading_df.loc[(trading_df[stock]['daily return'] < 0), (stock, 'signal')] = -1\n",
    "\n",
    "# Review the trading_df\n",
    "# Display the first and last five rows\n",
    "display(trading_df.head())\n",
    "display(trading_df.tail())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Copy the new \"signal\" column to a new Series called `y`.\n",
    "\n",
    "# Create y DataFrame\n",
    "y = pd.DataFrame(columns = trading_df.columns)\n",
    "\n",
    "# Re-define stock_ticker_list to ensure integrity\n",
    "stock_ticker_list = [\"AMAT\", \"AMD\", \"BHP\", \"DDD\", \"F\", \"FCX\", \"INTC\", \"MSFT\", \"NVDA\", \"QCOM\", \"RIO\", \"TSLA\", \"TSM\", \"VALE\"]\n",
    "\n",
    "# Assign a copy of the `signal` column to the new DataFrame called `y`\n",
    "# Loop through the trading_df\n",
    "for stock in stock_ticker_list:\n",
    "    y.loc[:,(stock, 'signal')] = trading_df[(stock, 'signal')].copy()\n",
    "\n",
    "# Drop columns other than signal\n",
    "y = y.drop(['close', 'daily return', 'lagged volume', 'sma_fast', 'sma_slow', 'stock volatility', 'volume'], axis='columns', level=1)\n",
    "\n",
    "# Display the first and last five rows of the y DataFrame\n",
    "display(y.head())\n",
    "display(y.tail())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Select the start of the training period\n",
    "training_begin = X.index.min()\n",
    "\n",
    "# Display the training begin date\n",
    "print(training_begin)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Select the ending period for the training data with an offset of 1 month\n",
    "training_end = X.index.min() + DateOffset(months=1)\n",
    "\n",
    "# Display the training end date\n",
    "print(training_end)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Generate the X_train and y_train DataFrames\n",
    "X_train = X.loc[training_begin:training_end]\n",
    "y_train = y.loc[training_begin:training_end]\n",
    "\n",
    "# Display sample data for X_train\n",
    "display(X_train.head(2))\n",
    "display(X_train.tail(2))\n",
    "\n",
    "# Display sample data for y_train\n",
    "display(y_train.head(2))\n",
    "display(y_train.tail(2))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Generate the Testing End\n",
    "testing_end = training_end + DateOffset(months=1)\n",
    "\n",
    "# Display the testing_end\n",
    "print(testing_end)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Generate the X_test and y_test DataFrames\n",
    "testing_end = training_end + DateOffset(months=1)\n",
    "X_test = X.loc[training_end:testing_end]\n",
    "y_test = y.loc[training_end:testing_end]\n",
    "\n",
    "# Display sample data for X_test\n",
    "display(X_test.head(2))\n",
    "display(X_test.tail(2))\n",
    "\n",
    "# Display sample data for y_test\n",
    "display(y_test.head(2))\n",
    "display(y_test.tail(2))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Stocks in Data Set are \"AMAT\", \"AMD\", \"BHP\", \"DDD\", \"F\", \"FCX\", \"INTC\", \"MSFT\", \"NVDA\", \"QCOM\", \"RIO\", \"TSLA\", \"TSM\", \"VALE\"\n",
    "\n",
    "# Create a StandardScaler instance\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# Apply the scaler model to fit the X_train data\n",
    "# X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Transform the X_train and X_test DataFrames using the X_scaler\n",
    "# X_train_scaled = X_scaler.transform(X_train)\n",
    "# X_test_scaled = X_scaler.transform(X_test)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create the classifier model\n",
    "# svm_model = svm.SVC()\n",
    "\n",
    "# Fit the model to the data using X_train_scaled and y_train\n",
    "# svm_model = svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Use the trained model to predict the trading signals for the training data\n",
    "# training_signal_predictions = svm_model.predict(X_train_scaled)\n",
    "\n",
    "# Display the sample predictions\n",
    "# training_signal_predictions"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Evaluate the model using a classification report\n",
    "# training_report = classification_report(y_train, training_signal_predictions)\n",
    "# print(training_report)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Stocks in Data Set are \"AMAT\", \"AMD\", \"BHP\", \"DDD\", \"F\", \"FCX\", \"INTC\", \"MSFT\", \"NVDA\", \"QCOM\", \"RIO\", \"TSLA\", \"TSM\", \"VALE\"\n",
    "\n",
    "# Create StandardScaler instances\n",
    "scaler_AMAT = StandardScaler()\n",
    "scaler_AMD = StandardScaler()\n",
    "scaler_BHP = StandardScaler()\n",
    "scaler_DDD = StandardScaler()\n",
    "scaler_F = StandardScaler()\n",
    "scaler_FCX = StandardScaler()\n",
    "scaler_INTC = StandardScaler()\n",
    "scaler_MSFT = StandardScaler()\n",
    "scaler_NVDA = StandardScaler()\n",
    "scaler_QCOM = StandardScaler()\n",
    "scaler_RIO = StandardScaler()\n",
    "scaler_TSLA = StandardScaler()\n",
    "scaler_TSM = StandardScaler()\n",
    "scaler_VALE = StandardScaler()\n",
    "\n",
    "# Apply the scaler model to fit the X_train data\n",
    "X_scaler_AMAT = scaler_AMAT.fit(X_train['AMAT'])\n",
    "X_scaler_AMD = scaler_AMD.fit(X_train['AMD'])\n",
    "X_scaler_BHP = scaler_BHP.fit(X_train['BHP'])\n",
    "X_scaler_DDD = scaler_DDD.fit(X_train['DDD'])\n",
    "X_scaler_F = scaler_F.fit(X_train['F'])\n",
    "X_scaler_FCX = scaler_FCX.fit(X_train['FCX'])\n",
    "X_scaler_INTC = scaler_INTC.fit(X_train['INTC'])\n",
    "X_scaler_MSFT = scaler_MSFT.fit(X_train['MSFT'])\n",
    "X_scaler_NVDA = scaler_NVDA.fit(X_train['NVDA'])\n",
    "X_scaler_QCOM = scaler_QCOM.fit(X_train['QCOM'])\n",
    "X_scaler_RIO = scaler_RIO.fit(X_train['RIO'])\n",
    "X_scaler_TSLA = scaler_TSLA.fit(X_train['TSLA'])\n",
    "X_scaler_TSM = scaler_TSM.fit(X_train['TSM'])\n",
    "X_scaler_VALE = scaler_VALE.fit(X_train['VALE'])\n",
    "\n",
    "# Transform the X_train and X_test DataFrames using the X_scaler\n",
    "X_train_AMAT_scaled = X_scaler_AMAT.transform(X_train['AMAT'])\n",
    "X_test_AMAT_scaled = X_scaler_AMAT.transform(X_test['AMAT'])\n",
    "\n",
    "X_train_AMD_scaled = X_scaler_AMD.transform(X_train['AMD'])\n",
    "X_test_AMD_scaled = X_scaler_AMD.transform(X_test['AMD'])\n",
    "\n",
    "X_train_BHP_scaled = X_scaler_BHP.transform(X_train['BHP'])\n",
    "X_test_BHP_scaled = X_scaler_BHP.transform(X_test['BHP'])\n",
    "\n",
    "X_train_DDD_scaled = X_scaler_DDD.transform(X_train['DDD'])\n",
    "X_test_DDD_scaled = X_scaler_DDD.transform(X_test['DDD'])\n",
    "\n",
    "X_train_F_scaled = X_scaler_F.transform(X_train['F'])\n",
    "X_test_F_scaled = X_scaler_F.transform(X_test['F'])\n",
    "\n",
    "X_train_FCX_scaled = X_scaler_FCX.transform(X_train['FCX'])\n",
    "X_test_FCX_scaled = X_scaler_FCX.transform(X_test['FCX'])\n",
    "\n",
    "X_train_INTC_scaled = X_scaler_INTC.transform(X_train['INTC'])\n",
    "X_test_INTC_scaled = X_scaler_INTC.transform(X_test['INTC'])\n",
    "\n",
    "X_train_MSFT_scaled = X_scaler_MSFT.transform(X_train['MSFT'])\n",
    "X_test_MSFT_scaled = X_scaler_MSFT.transform(X_test['MSFT'])\n",
    "\n",
    "X_train_NVDA_scaled = X_scaler_NVDA.transform(X_train['NVDA'])\n",
    "X_test_NVDA_scaled = X_scaler_NVDA.transform(X_test['NVDA'])\n",
    "\n",
    "X_train_QCOM_scaled = X_scaler_QCOM.transform(X_train['QCOM'])\n",
    "X_test_QCOM_scaled = X_scaler_QCOM.transform(X_test['QCOM'])\n",
    "\n",
    "X_train_RIO_scaled = X_scaler_RIO.transform(X_train['RIO'])\n",
    "X_test_RIO_scaled = X_scaler_RIO.transform(X_test['RIO'])\n",
    "\n",
    "X_train_TSLA_scaled = X_scaler_TSLA.transform(X_train['TSLA'])\n",
    "X_test_TSLA_scaled = X_scaler_TSLA.transform(X_test['TSLA'])\n",
    "\n",
    "X_train_TSM_scaled = X_scaler_TSM.transform(X_train['TSM'])\n",
    "X_test_TSM_scaled = X_scaler_TSM.transform(X_test['TSM'])\n",
    "\n",
    "X_train_VALE_scaled = X_scaler_VALE.transform(X_train['VALE'])\n",
    "X_test_VALE_scaled = X_scaler_VALE.transform(X_test['VALE'])\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Stocks in Data Set are \"AMAT\", \"AMD\", \"BHP\", \"DDD\", \"F\", \"FCX\", \"INTC\", \"MSFT\", \"NVDA\", \"QCOM\", \"RIO\", \"TSLA\", \"TSM\", \"VALE\"\n",
    "\n",
    "# Create the classifier model\n",
    "svm_model_1 = svm.SVC()\n",
    "svm_model_2 = svm.SVC()\n",
    "svm_model_3 = svm.SVC()\n",
    "svm_model_4 = svm.SVC()\n",
    "svm_model_5 = svm.SVC()\n",
    "svm_model_6 = svm.SVC()\n",
    "svm_model_7 = svm.SVC()\n",
    "svm_model_8 = svm.SVC()\n",
    "svm_model_9 = svm.SVC()\n",
    "svm_model_10 = svm.SVC()\n",
    "svm_model_11 = svm.SVC()\n",
    "svm_model_12 = svm.SVC()\n",
    "svm_model_13 = svm.SVC()\n",
    "svm_model_14 = svm.SVC()\n",
    "\n",
    "# Fit the model to the data using X_train_scaled and y_train\n",
    "svm_model_AMAT = svm_model_1.fit(X_train_AMAT_scaled, y_train['AMAT'])\n",
    "svm_model_AMD = svm_model_2.fit(X_train_AMD_scaled, y_train['AMD'])\n",
    "svm_model_BHP = svm_model_3.fit(X_train_BHP_scaled, y_train['BHP'])\n",
    "svm_model_DDD = svm_model_4.fit(X_train_DDD_scaled, y_train['DDD'])\n",
    "svm_model_F = svm_model_5.fit(X_train_F_scaled, y_train['F'])\n",
    "svm_model_FCX = svm_model_6.fit(X_train_FCX_scaled, y_train['FCX'])\n",
    "svm_model_INTC = svm_model_7.fit(X_train_INTC_scaled, y_train['INTC'])\n",
    "svm_model_MSFT = svm_model_8.fit(X_train_MSFT_scaled, y_train['MSFT'])\n",
    "svm_model_NVDA = svm_model_9.fit(X_train_NVDA_scaled, y_train['NVDA'])\n",
    "svm_model_QCOM = svm_model_10.fit(X_train_QCOM_scaled, y_train['QCOM'])\n",
    "svm_model_RIO = svm_model_11.fit(X_train_RIO_scaled, y_train['RIO'])\n",
    "svm_model_TSLA = svm_model_12.fit(X_train_TSLA_scaled, y_train['TSLA'])\n",
    "svm_model_TSM = svm_model_13.fit(X_train_TSM_scaled, y_train['TSM'])\n",
    "svm_model_VALE = svm_model_14.fit(X_train_VALE_scaled, y_train['VALE'])\n",
    "\n",
    "# Use the trained model to predict the trading signals for the training data\n",
    "training_signal_predictions_AMAT = svm_model_AMAT.predict(X_train_AMAT_scaled)\n",
    "training_signal_predictions_AMD = svm_model_AMD.predict(X_train_AMD_scaled)\n",
    "training_signal_predictions_BHP = svm_model_BHP.predict(X_train_BHP_scaled)\n",
    "training_signal_predictions_DDD = svm_model_DDD.predict(X_train_DDD_scaled)\n",
    "training_signal_predictions_F = svm_model_F.predict(X_train_F_scaled)\n",
    "training_signal_predictions_FCX = svm_model_FCX.predict(X_train_FCX_scaled)\n",
    "training_signal_predictions_INTC = svm_model_INTC.predict(X_train_INTC_scaled)\n",
    "training_signal_predictions_MSFT = svm_model_MSFT.predict(X_train_MSFT_scaled)\n",
    "training_signal_predictions_NVDA = svm_model_NVDA.predict(X_train_NVDA_scaled)\n",
    "training_signal_predictions_QCOM = svm_model_QCOM.predict(X_train_QCOM_scaled)\n",
    "training_signal_predictions_RIO = svm_model_RIO.predict(X_train_RIO_scaled)\n",
    "training_signal_predictions_TSLA = svm_model_TSLA.predict(X_train_TSLA_scaled)\n",
    "training_signal_predictions_TSM = svm_model_TSM.predict(X_train_TSM_scaled)\n",
    "training_signal_predictions_VALE = svm_model_VALE.predict(X_train_VALE_scaled)\n",
    "\n",
    "# Display the sample predictions for AMAT\n",
    "training_signal_predictions_AMAT[:10]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Stocks in Data Set are \"AMAT\", \"AMD\", \"BHP\", \"DDD\", \"F\", \"FCX\", \"INTC\", \"MSFT\", \"NVDA\", \"QCOM\", \"RIO\", \"TSLA\", \"TSM\", \"VALE\"\n",
    "\n",
    "# Evaluate the model using a classification report for each of the stocks\n",
    "training_report_AMAT = classification_report(y_train['AMAT'], training_signal_predictions_AMAT)\n",
    "training_report_AMD = classification_report(y_train['AMD'], training_signal_predictions_AMD)\n",
    "training_report_BHP = classification_report(y_train['BHP'], training_signal_predictions_BHP)\n",
    "training_report_DDD = classification_report(y_train['DDD'], training_signal_predictions_DDD)\n",
    "training_report_F = classification_report(y_train['F'], training_signal_predictions_F)\n",
    "training_report_FCX = classification_report(y_train['FCX'], training_signal_predictions_FCX)\n",
    "training_report_INTC = classification_report(y_train['INTC'], training_signal_predictions_INTC)\n",
    "training_report_MSFT = classification_report(y_train['MSFT'], training_signal_predictions_MSFT)\n",
    "training_report_NVDA = classification_report(y_train['NVDA'], training_signal_predictions_NVDA)\n",
    "training_report_QCOM = classification_report(y_train['QCOM'], training_signal_predictions_QCOM)\n",
    "training_report_RIO = classification_report(y_train['RIO'], training_signal_predictions_RIO)\n",
    "training_report_TSLA = classification_report(y_train['TSLA'], training_signal_predictions_TSLA)\n",
    "training_report_TSM = classification_report(y_train['TSM'], training_signal_predictions_TSM)\n",
    "training_report_VALE = classification_report(y_train['VALE'], training_signal_predictions_VALE)\n",
    "\n",
    "# Display the Classification Reports\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"AMAT Training Report\")\n",
    "print(training_report_AMAT)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"AMD Training Report\")\n",
    "print(training_report_AMD)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"BHP Training Report\")\n",
    "print(training_report_BHP)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"DDD Training Report\")\n",
    "print(training_report_DDD)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"F Training Report\")\n",
    "print(training_report_F)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"FCX Training Report\")\n",
    "print(training_report_FCX)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"INTC Training Report\")\n",
    "print(training_report_INTC)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"MSFT Training Report\")\n",
    "print(training_report_MSFT)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"NVDA Training Report\")\n",
    "print(training_report_NVDA)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"QCOM Training Report\")\n",
    "print(training_report_QCOM)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"RIO Training Report\")\n",
    "print(training_report_RIO)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"TSLA Training Report\")\n",
    "print(training_report_TSLA)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"TSM Training Report\")\n",
    "print(training_report_TSM)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"VALE Training Report\")\n",
    "print(training_report_VALE)\n",
    "\n",
    "print(\"----------------------------\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Backtesting"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Stocks in Data Set are \"AMAT\", \"AMD\", \"BHP\", \"DDD\", \"F\", \"FCX\", \"INTC\", \"MSFT\", \"NVDA\", \"QCOM\", \"RIO\", \"TSLA\", \"TSM\", \"VALE\"\n",
    "\n",
    "# Use the trained models to predict the trading signals for the testing data.\n",
    "testing_signal_predictions_AMAT = svm_model_AMAT.predict(X_test_AMAT_scaled)\n",
    "testing_signal_predictions_AMD = svm_model_AMD.predict(X_test_AMD_scaled)\n",
    "testing_signal_predictions_BHP = svm_model_BHP.predict(X_test_BHP_scaled)\n",
    "testing_signal_predictions_DDD = svm_model_DDD.predict(X_test_DDD_scaled)\n",
    "testing_signal_predictions_F = svm_model_F.predict(X_test_F_scaled)\n",
    "testing_signal_predictions_FCX = svm_model_FCX.predict(X_test_FCX_scaled)\n",
    "testing_signal_predictions_INTC = svm_model_INTC.predict(X_test_INTC_scaled)\n",
    "testing_signal_predictions_MSFT = svm_model_MSFT.predict(X_test_MSFT_scaled)\n",
    "testing_signal_predictions_NVDA = svm_model_NVDA.predict(X_test_NVDA_scaled)\n",
    "testing_signal_predictions_QCOM = svm_model_QCOM.predict(X_test_QCOM_scaled)\n",
    "testing_signal_predictions_RIO = svm_model_RIO.predict(X_test_RIO_scaled)\n",
    "testing_signal_predictions_TSLA = svm_model_TSLA.predict(X_test_TSLA_scaled)\n",
    "testing_signal_predictions_TSM = svm_model_TSM.predict(X_test_TSM_scaled)\n",
    "testing_signal_predictions_VALE = svm_model_VALE.predict(X_test_VALE_scaled)\n",
    "\n",
    "# Evaluate the model's ability to predict the trading signal for the testing data\n",
    "testing_report_AMAT = classification_report(y_test['AMAT'], testing_signal_predictions_AMAT)\n",
    "testing_report_AMD = classification_report(y_test['AMD'], testing_signal_predictions_AMD)\n",
    "testing_report_BHP = classification_report(y_test['BHP'], testing_signal_predictions_BHP)\n",
    "testing_report_DDD = classification_report(y_test['DDD'], testing_signal_predictions_DDD)\n",
    "testing_report_F = classification_report(y_test['F'], testing_signal_predictions_F)\n",
    "testing_report_FCX = classification_report(y_test['FCX'], testing_signal_predictions_FCX)\n",
    "testing_report_INTC = classification_report(y_test['INTC'], testing_signal_predictions_INTC)\n",
    "testing_report_MSFT = classification_report(y_test['MSFT'], testing_signal_predictions_MSFT)\n",
    "testing_report_NVDA = classification_report(y_test['NVDA'], testing_signal_predictions_NVDA)\n",
    "testing_report_QCOM = classification_report(y_test['QCOM'], testing_signal_predictions_QCOM)\n",
    "testing_report_RIO = classification_report(y_test['RIO'], testing_signal_predictions_RIO)\n",
    "testing_report_TSLA = classification_report(y_test['TSLA'], testing_signal_predictions_TSLA)\n",
    "testing_report_TSM = classification_report(y_test['TSM'], testing_signal_predictions_TSM)\n",
    "testing_report_VALE = classification_report(y_test['VALE'], testing_signal_predictions_VALE)\n",
    "\n",
    "# Display the Classification Reports\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"AMAT Testing Report\")\n",
    "print(testing_report_AMAT)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"AMD Testing Report\")\n",
    "print(testing_report_AMD)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"BHP Testing Report\")\n",
    "print(testing_report_BHP)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"DDD Testing Report\")\n",
    "print(testing_report_DDD)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"F Testing Report\")\n",
    "print(testing_report_F)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"FCX Testing Report\")\n",
    "print(testing_report_FCX)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"INTC Testing Report\")\n",
    "print(testing_report_INTC)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"MSFT Testing Report\")\n",
    "print(testing_report_MSFT)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"NVDA Testing Report\")\n",
    "print(testing_report_NVDA)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"QCOM Testing Report\")\n",
    "print(testing_report_QCOM)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"RIO Testing Report\")\n",
    "print(testing_report_RIO)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"TSLA Testing Report\")\n",
    "print(testing_report_TSLA)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"TSM Testing Report\")\n",
    "print(testing_report_TSM)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"VALE Testing Report\")\n",
    "print(testing_report_VALE)\n",
    "\n",
    "print(\"----------------------------\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('algo': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "83ff2463df67d4299958bd5f4082f8634e97706bb1a9308762362deea05bac91"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}