{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# <font color=LightSalmon>Import Libraries and Create REST Object</font>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Initial imports\n",
    "import os\n",
    "import csv\n",
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import alpaca_trade_api as tradeapi\n",
    "\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Load the environment variables by calling the load_dotenv function\n",
    "load_dotenv()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Python-dotenv could not parse statement starting at line 1\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Set Alpaca API and secret keys to env variables\n",
    "alpaca_api_key = os.getenv(\"ALPACA_API_KEY\")\n",
    "alpaca_secret_key = os.getenv(\"ALPACA_SECRET_KEY\")\n",
    "\n",
    "# Check the values were imported correctly by evaluating the type of each\n",
    "display(type(alpaca_api_key))\n",
    "display(type(alpaca_secret_key))\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create your Alpaca API REST object by calling Alpaca's tradeapi.REST function\n",
    "alpaca = tradeapi.REST(\n",
    "    alpaca_api_key,\n",
    "    alpaca_secret_key,\n",
    "    api_version=\"v2\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <font color=LightSalmon>Set Arguments and Retrieve Data</font>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <font color=MediumSlateBlue>Set Arguments</font>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Format the current date as ISO format\n",
    "today = pd.Timestamp(\"2021-09-28\", tz=\"America/New_York\").isoformat()\n",
    "\n",
    "# Set tickers for chosen stock portfolio\n",
    "tickers = [\"TSM\", \"QCOM\", \"VALE\", \"AMD\", \"BHP\", \"RIO\", \"FCX\", \"INTC\", \"MSFT\", \"DDD\", \"NVDA\", \"TSLA\", \"AMAT\", \"F\", \"VOO\"]\n",
    "\n",
    "# Set timeframe to one day ('1D') for the Alpaca API\n",
    "timeframe = \"1D\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <font color=MediumSlateBlue>Confirm Proper API Functionality</font>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Get current closing prices for above stocks\n",
    "df_portfolio = alpaca.get_barset(\n",
    "    tickers,\n",
    "    timeframe,\n",
    "    start = today,\n",
    "    end = today,\n",
    "    limit = 500\n",
    ").df\n",
    "\n",
    "# Display sample data\n",
    "# Auto formats in alphabetical order\n",
    "df_portfolio"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">AMAT</th>\n",
       "      <th colspan=\"5\" halign=\"left\">AMD</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"5\" halign=\"left\">VALE</th>\n",
       "      <th colspan=\"5\" halign=\"left\">VOO</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>...</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-09-28 00:00:00-04:00</th>\n",
       "      <td>137.62</td>\n",
       "      <td>139.58</td>\n",
       "      <td>132.5339</td>\n",
       "      <td>132.91</td>\n",
       "      <td>10774137</td>\n",
       "      <td>106.79</td>\n",
       "      <td>107.65</td>\n",
       "      <td>101.42</td>\n",
       "      <td>101.52</td>\n",
       "      <td>71109820</td>\n",
       "      <td>...</td>\n",
       "      <td>14.35</td>\n",
       "      <td>14.41</td>\n",
       "      <td>13.76</td>\n",
       "      <td>13.8</td>\n",
       "      <td>39804576</td>\n",
       "      <td>405.53</td>\n",
       "      <td>405.87</td>\n",
       "      <td>399.33</td>\n",
       "      <td>400.09</td>\n",
       "      <td>7903801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             AMAT                                         AMD  \\\n",
       "                             open    high       low   close    volume    open   \n",
       "time                                                                            \n",
       "2021-09-28 00:00:00-04:00  137.62  139.58  132.5339  132.91  10774137  106.79   \n",
       "\n",
       "                                                             ...   VALE  \\\n",
       "                             high     low   close    volume  ...   open   \n",
       "time                                                         ...          \n",
       "2021-09-28 00:00:00-04:00  107.65  101.42  101.52  71109820  ...  14.35   \n",
       "\n",
       "                                                            VOO          \\\n",
       "                            high    low close    volume    open    high   \n",
       "time                                                                      \n",
       "2021-09-28 00:00:00-04:00  14.41  13.76  13.8  39804576  405.53  405.87   \n",
       "\n",
       "                                                    \n",
       "                              low   close   volume  \n",
       "time                                                \n",
       "2021-09-28 00:00:00-04:00  399.33  400.09  7903801  \n",
       "\n",
       "[1 rows x 75 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <font color=MediumSlateBlue>Pull Data for Analysis</font>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Condensed function for pulling a year's worth of data\n",
    "\n",
    "start_date_string = '2020-05-28'\n",
    "\n",
    "# number of months worth of data to pull\n",
    "# use a number divisible by 4\n",
    "months_of_data = 12\n",
    "\n",
    "# largest period the Alpaca API will pull per call\n",
    "api_constant = 4\n",
    "\n",
    "# calculate number of api calls\n",
    "api_calls = int(months_of_data / api_constant)\n",
    "\n",
    "# identify last api call\n",
    "last_call = api_calls - 1\n",
    "\n",
    "# create dataframe to hold results of API calls\n",
    "portfolio_data = pd.DataFrame()\n",
    "\n",
    "# api call results columns to drop\n",
    "api_drops = ['open', 'low', 'high']\n",
    "\n",
    "# iterate calculated number of API calls\n",
    "for idx in range(api_calls):\n",
    "\n",
    "    # establish start and end dates\n",
    "    # first call\n",
    "    if idx == 0:\n",
    "        start_ts = pd.Timestamp(start_date_string, tz='America/New_York')\n",
    "        end_ts = start_ts + DateOffset(months=api_constant)\n",
    "    # last call\n",
    "    elif idx == last_call:\n",
    "        start_ts = end_ts\n",
    "        end_ts = start_ts \\\n",
    "            + DateOffset(months=api_constant) \\\n",
    "            - DateOffset(days=1)\n",
    "    # all other calls\n",
    "    else:\n",
    "        start_ts = end_ts\n",
    "        end_ts = start_ts + DateOffset(months=api_constant)\n",
    "    \n",
    "    start_iso = start_ts.isoformat()\n",
    "    end_iso = end_ts.isoformat()\n",
    "\n",
    "    api_app_df = pd.DataFrame()\n",
    "\n",
    "    api_app_df = alpaca.get_barset(\n",
    "        tickers,\n",
    "        timeframe,\n",
    "        start = start_iso,\n",
    "        end = end_iso,\n",
    "        limit = 1000\n",
    "    ).df\n",
    "\n",
    "    api_app_df['droptime'] = api_app_df.index.to_list()\n",
    "    api_app_df['droptime'] = pd.to_datetime(api_app_df['droptime']).dt.date\n",
    "    api_app_df.set_index('droptime', inplace=True)\n",
    "\n",
    "    api_app_df = api_app_df.drop(api_drops, axis=1, level=1)\n",
    "\n",
    "    print(f'Dates:\\n\\tstart: {start_iso}\\n\\tend: {end_iso}\\n-----')\n",
    "\n",
    "    if len(portfolio_data) == 0:\n",
    "       portfolio_data = api_app_df.copy()\n",
    "    else:\n",
    "        portfolio_data = pd.concat([portfolio_data, api_app_df])\n",
    "\n",
    "portfolio_data"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dates:\n",
      "\tstart: 2020-05-28T00:00:00-04:00\n",
      "\tend: 2020-09-28T00:00:00-04:00\n",
      "-----\n",
      "Dates:\n",
      "\tstart: 2020-09-28T00:00:00-04:00\n",
      "\tend: 2021-01-28T00:00:00-05:00\n",
      "-----\n",
      "Dates:\n",
      "\tstart: 2021-01-28T00:00:00-05:00\n",
      "\tend: 2021-05-27T00:00:00-04:00\n",
      "-----\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">AMAT</th>\n",
       "      <th colspan=\"2\" halign=\"left\">AMD</th>\n",
       "      <th colspan=\"2\" halign=\"left\">BHP</th>\n",
       "      <th colspan=\"2\" halign=\"left\">DDD</th>\n",
       "      <th colspan=\"2\" halign=\"left\">F</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">RIO</th>\n",
       "      <th colspan=\"2\" halign=\"left\">TSLA</th>\n",
       "      <th colspan=\"2\" halign=\"left\">TSM</th>\n",
       "      <th colspan=\"2\" halign=\"left\">VALE</th>\n",
       "      <th colspan=\"2\" halign=\"left\">VOO</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>...</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>droptime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-05-28</th>\n",
       "      <td>54.67</td>\n",
       "      <td>6158997.0</td>\n",
       "      <td>51.7600</td>\n",
       "      <td>50946899</td>\n",
       "      <td>46.70</td>\n",
       "      <td>2281896</td>\n",
       "      <td>7.545</td>\n",
       "      <td>2088095</td>\n",
       "      <td>5.845</td>\n",
       "      <td>147780238</td>\n",
       "      <td>...</td>\n",
       "      <td>52.51</td>\n",
       "      <td>4369514.0</td>\n",
       "      <td>805.9750</td>\n",
       "      <td>7013890</td>\n",
       "      <td>50.325</td>\n",
       "      <td>15061972</td>\n",
       "      <td>9.305</td>\n",
       "      <td>22393780</td>\n",
       "      <td>278.53</td>\n",
       "      <td>8708139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-29</th>\n",
       "      <td>56.30</td>\n",
       "      <td>13723212.0</td>\n",
       "      <td>53.6839</td>\n",
       "      <td>112901502</td>\n",
       "      <td>47.11</td>\n",
       "      <td>3421150</td>\n",
       "      <td>7.380</td>\n",
       "      <td>1684311</td>\n",
       "      <td>5.705</td>\n",
       "      <td>164536966</td>\n",
       "      <td>...</td>\n",
       "      <td>53.98</td>\n",
       "      <td>5041990.0</td>\n",
       "      <td>834.1905</td>\n",
       "      <td>10523947</td>\n",
       "      <td>50.450</td>\n",
       "      <td>18952949</td>\n",
       "      <td>9.795</td>\n",
       "      <td>33798904</td>\n",
       "      <td>279.60</td>\n",
       "      <td>11883437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-01</th>\n",
       "      <td>55.68</td>\n",
       "      <td>9909190.0</td>\n",
       "      <td>53.6250</td>\n",
       "      <td>70439736</td>\n",
       "      <td>48.25</td>\n",
       "      <td>2036048</td>\n",
       "      <td>7.615</td>\n",
       "      <td>1818055</td>\n",
       "      <td>5.870</td>\n",
       "      <td>117398954</td>\n",
       "      <td>...</td>\n",
       "      <td>54.88</td>\n",
       "      <td>3324520.0</td>\n",
       "      <td>897.8750</td>\n",
       "      <td>13962296</td>\n",
       "      <td>51.020</td>\n",
       "      <td>11648942</td>\n",
       "      <td>9.850</td>\n",
       "      <td>25548266</td>\n",
       "      <td>280.92</td>\n",
       "      <td>6366464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-02</th>\n",
       "      <td>55.80</td>\n",
       "      <td>12075052.0</td>\n",
       "      <td>53.5500</td>\n",
       "      <td>80457250</td>\n",
       "      <td>49.77</td>\n",
       "      <td>2719198</td>\n",
       "      <td>7.870</td>\n",
       "      <td>1946154</td>\n",
       "      <td>5.900</td>\n",
       "      <td>150478330</td>\n",
       "      <td>...</td>\n",
       "      <td>55.75</td>\n",
       "      <td>6085314.0</td>\n",
       "      <td>881.4000</td>\n",
       "      <td>13049927</td>\n",
       "      <td>52.000</td>\n",
       "      <td>11482022</td>\n",
       "      <td>10.250</td>\n",
       "      <td>27910958</td>\n",
       "      <td>283.26</td>\n",
       "      <td>8073308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-03</th>\n",
       "      <td>57.80</td>\n",
       "      <td>13789624.0</td>\n",
       "      <td>52.7250</td>\n",
       "      <td>89070416</td>\n",
       "      <td>50.46</td>\n",
       "      <td>1612726</td>\n",
       "      <td>8.110</td>\n",
       "      <td>2367528</td>\n",
       "      <td>6.190</td>\n",
       "      <td>186704966</td>\n",
       "      <td>...</td>\n",
       "      <td>56.53</td>\n",
       "      <td>3534218.0</td>\n",
       "      <td>882.5100</td>\n",
       "      <td>15342518</td>\n",
       "      <td>53.060</td>\n",
       "      <td>15910976</td>\n",
       "      <td>10.580</td>\n",
       "      <td>32676829</td>\n",
       "      <td>287.02</td>\n",
       "      <td>10621584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-22</th>\n",
       "      <td>57.87</td>\n",
       "      <td>6581826.0</td>\n",
       "      <td>77.7100</td>\n",
       "      <td>52638614</td>\n",
       "      <td>52.89</td>\n",
       "      <td>1200973</td>\n",
       "      <td>4.970</td>\n",
       "      <td>2027281</td>\n",
       "      <td>6.770</td>\n",
       "      <td>52264085</td>\n",
       "      <td>...</td>\n",
       "      <td>61.41</td>\n",
       "      <td>1774690.0</td>\n",
       "      <td>423.9740</td>\n",
       "      <td>66119366</td>\n",
       "      <td>80.480</td>\n",
       "      <td>6094806</td>\n",
       "      <td>10.650</td>\n",
       "      <td>28273811</td>\n",
       "      <td>304.72</td>\n",
       "      <td>2356094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-23</th>\n",
       "      <td>57.27</td>\n",
       "      <td>7731718.0</td>\n",
       "      <td>74.7500</td>\n",
       "      <td>39318292</td>\n",
       "      <td>51.83</td>\n",
       "      <td>1950527</td>\n",
       "      <td>4.730</td>\n",
       "      <td>2725064</td>\n",
       "      <td>6.635</td>\n",
       "      <td>45833211</td>\n",
       "      <td>...</td>\n",
       "      <td>60.41</td>\n",
       "      <td>1783104.0</td>\n",
       "      <td>380.3885</td>\n",
       "      <td>88358954</td>\n",
       "      <td>77.900</td>\n",
       "      <td>7697335</td>\n",
       "      <td>10.650</td>\n",
       "      <td>78475263</td>\n",
       "      <td>297.66</td>\n",
       "      <td>2708206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-24</th>\n",
       "      <td>57.81</td>\n",
       "      <td>5731409.0</td>\n",
       "      <td>75.8150</td>\n",
       "      <td>55008161</td>\n",
       "      <td>52.63</td>\n",
       "      <td>1785649</td>\n",
       "      <td>4.660</td>\n",
       "      <td>2217432</td>\n",
       "      <td>6.650</td>\n",
       "      <td>49319742</td>\n",
       "      <td>...</td>\n",
       "      <td>61.17</td>\n",
       "      <td>1563061.0</td>\n",
       "      <td>387.6300</td>\n",
       "      <td>93527446</td>\n",
       "      <td>78.390</td>\n",
       "      <td>8776268</td>\n",
       "      <td>10.700</td>\n",
       "      <td>68270250</td>\n",
       "      <td>298.47</td>\n",
       "      <td>3085717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-25</th>\n",
       "      <td>58.22</td>\n",
       "      <td>5579547.0</td>\n",
       "      <td>78.0500</td>\n",
       "      <td>45258205</td>\n",
       "      <td>52.39</td>\n",
       "      <td>2200475</td>\n",
       "      <td>4.645</td>\n",
       "      <td>1934466</td>\n",
       "      <td>6.510</td>\n",
       "      <td>46001365</td>\n",
       "      <td>...</td>\n",
       "      <td>60.38</td>\n",
       "      <td>2108335.0</td>\n",
       "      <td>407.1800</td>\n",
       "      <td>64600754</td>\n",
       "      <td>78.880</td>\n",
       "      <td>5190308</td>\n",
       "      <td>10.740</td>\n",
       "      <td>39751123</td>\n",
       "      <td>303.23</td>\n",
       "      <td>2499756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-28</th>\n",
       "      <td>59.31</td>\n",
       "      <td>6260486.0</td>\n",
       "      <td>79.5200</td>\n",
       "      <td>43111531</td>\n",
       "      <td>52.74</td>\n",
       "      <td>1874323</td>\n",
       "      <td>4.790</td>\n",
       "      <td>1710523</td>\n",
       "      <td>6.695</td>\n",
       "      <td>43985784</td>\n",
       "      <td>...</td>\n",
       "      <td>60.50</td>\n",
       "      <td>3067588.0</td>\n",
       "      <td>421.0602</td>\n",
       "      <td>46468845</td>\n",
       "      <td>79.770</td>\n",
       "      <td>5615288</td>\n",
       "      <td>10.480</td>\n",
       "      <td>37147138</td>\n",
       "      <td>308.32</td>\n",
       "      <td>2376657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             AMAT                  AMD               BHP             DDD  \\\n",
       "            close      volume    close     volume  close   volume  close   \n",
       "droptime                                                                   \n",
       "2020-05-28  54.67   6158997.0  51.7600   50946899  46.70  2281896  7.545   \n",
       "2020-05-29  56.30  13723212.0  53.6839  112901502  47.11  3421150  7.380   \n",
       "2020-06-01  55.68   9909190.0  53.6250   70439736  48.25  2036048  7.615   \n",
       "2020-06-02  55.80  12075052.0  53.5500   80457250  49.77  2719198  7.870   \n",
       "2020-06-03  57.80  13789624.0  52.7250   89070416  50.46  1612726  8.110   \n",
       "...           ...         ...      ...        ...    ...      ...    ...   \n",
       "2020-09-22  57.87   6581826.0  77.7100   52638614  52.89  1200973  4.970   \n",
       "2020-09-23  57.27   7731718.0  74.7500   39318292  51.83  1950527  4.730   \n",
       "2020-09-24  57.81   5731409.0  75.8150   55008161  52.63  1785649  4.660   \n",
       "2020-09-25  58.22   5579547.0  78.0500   45258205  52.39  2200475  4.645   \n",
       "2020-09-28  59.31   6260486.0  79.5200   43111531  52.74  1874323  4.790   \n",
       "\n",
       "                         F             ...    RIO                 TSLA  \\\n",
       "             volume  close     volume  ...  close     volume     close   \n",
       "droptime                               ...                               \n",
       "2020-05-28  2088095  5.845  147780238  ...  52.51  4369514.0  805.9750   \n",
       "2020-05-29  1684311  5.705  164536966  ...  53.98  5041990.0  834.1905   \n",
       "2020-06-01  1818055  5.870  117398954  ...  54.88  3324520.0  897.8750   \n",
       "2020-06-02  1946154  5.900  150478330  ...  55.75  6085314.0  881.4000   \n",
       "2020-06-03  2367528  6.190  186704966  ...  56.53  3534218.0  882.5100   \n",
       "...             ...    ...        ...  ...    ...        ...       ...   \n",
       "2020-09-22  2027281  6.770   52264085  ...  61.41  1774690.0  423.9740   \n",
       "2020-09-23  2725064  6.635   45833211  ...  60.41  1783104.0  380.3885   \n",
       "2020-09-24  2217432  6.650   49319742  ...  61.17  1563061.0  387.6300   \n",
       "2020-09-25  1934466  6.510   46001365  ...  60.38  2108335.0  407.1800   \n",
       "2020-09-28  1710523  6.695   43985784  ...  60.50  3067588.0  421.0602   \n",
       "\n",
       "                         TSM              VALE               VOO            \n",
       "              volume   close    volume   close    volume   close    volume  \n",
       "droptime                                                                    \n",
       "2020-05-28   7013890  50.325  15061972   9.305  22393780  278.53   8708139  \n",
       "2020-05-29  10523947  50.450  18952949   9.795  33798904  279.60  11883437  \n",
       "2020-06-01  13962296  51.020  11648942   9.850  25548266  280.92   6366464  \n",
       "2020-06-02  13049927  52.000  11482022  10.250  27910958  283.26   8073308  \n",
       "2020-06-03  15342518  53.060  15910976  10.580  32676829  287.02  10621584  \n",
       "...              ...     ...       ...     ...       ...     ...       ...  \n",
       "2020-09-22  66119366  80.480   6094806  10.650  28273811  304.72   2356094  \n",
       "2020-09-23  88358954  77.900   7697335  10.650  78475263  297.66   2708206  \n",
       "2020-09-24  93527446  78.390   8776268  10.700  68270250  298.47   3085717  \n",
       "2020-09-25  64600754  78.880   5190308  10.740  39751123  303.23   2499756  \n",
       "2020-09-28  46468845  79.770   5615288  10.480  37147138  308.32   2376657  \n",
       "\n",
       "[86 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "testing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "start = pd.Timestamp(\"2020-05-28\", tz=\"America/New_York\")\n",
    "\n",
    "four_month = start + DateOffset(months=4)\n",
    "\n",
    "start = start.isoformat()\n",
    "four_month = four_month.isoformat()\n",
    "\n",
    "print(f'start date: {start}')\n",
    "\n",
    "print(f'four month offset: {four_month}')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "original code"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# The furthest Alpaca will go back is 4 months for one pull\n",
    "# Format start and end dates as ISO format for one year period\n",
    "start = pd.Timestamp(\"2021-05-28\", tz=\"America/New_York\").isoformat()\n",
    "end = pd.Timestamp(\"2021-09-28\", tz=\"America/New_York\").isoformat()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Get closing prices for chosen stocks from start to end date\n",
    "df_portfolio_months = alpaca.get_barset(\n",
    "    tickers,\n",
    "    timeframe,\n",
    "    start = start,\n",
    "    end = end,\n",
    "    limit = 1000\n",
    ").df\n",
    "\n",
    "# Display sample data\n",
    "df_portfolio_months.head(10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(df_portfolio_months)\n",
    "print(df_portfolio_months.duplicated(keep='first').value_counts())\n",
    "print(len(df_portfolio_months))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Clean the data and drop all columns except for closing\n",
    "df_portfolio_months_clean = df_portfolio_months.drop(['open', 'low', 'high'], axis=1, level=1)\n",
    "\n",
    "# Display sample data\n",
    "df_portfolio_months_clean.head(10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# The farthest Alpaca will go back is 4 months for one pull, so we repeat process below\n",
    "# Format start and end dates as ISO format for four month period\n",
    "# Use the start date above as the end date below\n",
    "start_2 = pd.Timestamp(\"2021-01-01\", tz=\"America/New_York\").isoformat()\n",
    "end_2 = pd.Timestamp(\"2021-05-27\", tz=\"America/New_York\").isoformat()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Get closing prices for chosen stocks from start to end date of choice\n",
    "df_portfolio_months_2 = alpaca.get_barset(\n",
    "    tickers,\n",
    "    timeframe,\n",
    "    start = start_2,\n",
    "    end = end_2,\n",
    "    limit = 1000\n",
    ").df\n",
    "\n",
    "# Clean the data and drop all columns except for closing\n",
    "df_portfolio_months_2_clean = df_portfolio_months_2.drop(['open', 'low', 'high'], axis=1, level=1)\n",
    "\n",
    "# Display sample data\n",
    "df_portfolio_months_2_clean.head(10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# The farthest Alpaca will go back is 4 months for one pull, so we repeat process below\n",
    "# Format start and end dates as ISO format for four month period\n",
    "# Use the start date above as the end date below\n",
    "\n",
    "start_3 = pd.Timestamp(\"2020-09-28\", tz=\"America/New_York\").isoformat()\n",
    "end_3 = pd.Timestamp(\"2021-01-01\", tz=\"America/New_York\").isoformat()\n",
    "\n",
    "df_portfolio_months_3 = alpaca.get_barset(\n",
    "    tickers,\n",
    "    timeframe,\n",
    "    start = start_3,\n",
    "    end = end_3,\n",
    "    limit = 1000\n",
    ").df\n",
    "\n",
    "# Clean the data and drop all columns except for closing\n",
    "df_portfolio_months_3_clean = df_portfolio_months_3.drop(['open', 'low', 'high'], axis=1, level=1)\n",
    "\n",
    "# Display sample data\n",
    "df_portfolio_months_3_clean"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Combine all the cleaned data into one table by using concat\n",
    "merged_portfolio = pd.concat([df_portfolio_months_3_clean, df_portfolio_months_2_clean, df_portfolio_months_clean])\n",
    "\n",
    "# Display newly merged portfolio\n",
    "merged_portfolio"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Assign save path to variable\n",
    "save_path = Path('./cleaned_stock_data.csv')\n",
    "\n",
    "# Send to CSV file if file does not already exist\n",
    "if not save_path.is_file():\n",
    "    merged_portfolio.to_csv(save_path)\n",
    "else:\n",
    "    # alright, proceed...\n",
    "    print('csv output not resaved.')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <font color=LightSalmon>Plot Portfolio Closing Prices</font>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Graph your stocks closing prices over the course of the last year by using the data you just merged into one portfolio\n",
    "# We are graphing the data to get a visualization over the stock closing price performance over the last year\n",
    "\n",
    "# First remove the volume column from the portfolio to just plot the closing prices\n",
    "merged_portfolio_close_dates = merged_portfolio.drop(['volume'], axis=1, level=1)\n",
    "\n",
    "merged_portfolio_close_dates.plot()\n",
    "plt.title('Full Calendar Year of Closing Prices for Chosen Stocks')\n",
    "plt.ylabel('Closing Prices')\n",
    "plt.xlabel('Date')\n",
    "plt.legend(loc=\"lower right\", bbox_to_anchor=(1.4, -0.19), ncol=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Graph your stocks daily volume over the course of the last year by using the data you just merged into one portfolio\n",
    "# We are graphing the data to get a visualization over the changes in volume over the last year\n",
    "\n",
    "# First remove the close column from the portfolio to just plot the volume\n",
    "merged_portfolio_volumes = merged_portfolio.drop(['close'], axis=1, level=1)\n",
    "\n",
    "merged_portfolio_volumes.plot()\n",
    "plt.title('Full Calendar Year of Volume for Chosen Stocks')\n",
    "plt.ylabel('Volume')\n",
    "plt.xlabel('Date')\n",
    "plt.legend(loc=\"lower right\", bbox_to_anchor=(1.4, -0.19), ncol=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a Lagged Volume column that shifts the volume of each stock back by one day\n",
    "\n",
    "# Since there are multiple columns with the name volume, we must create a loop \n",
    "for widget in merged_portfolio.columns.levels[0]:\n",
    "    merged_portfolio.loc[:,(widget, 'lagged volume')] = merged_portfolio[(widget, 'volume')].shift(1)\n",
    "\n",
    "# Then we sort the columns to show within each stock\n",
    "merged_portfolio = merged_portfolio.sort_index(axis=1, level=0)\n",
    "\n",
    "#Drop NA values\n",
    "merged_portfolio.dropna(inplace=True)\n",
    "\n",
    "#Display portfolio \n",
    "merged_portfolio.head(10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a Daily Stock Return column that will calculate the daily percent change of the closing stock prices\n",
    "\n",
    "# Since there are multiple columns with the name close, we must create a loop \n",
    "\n",
    "for stock in merged_portfolio.columns.levels[0]:\n",
    "    merged_portfolio.loc[:,(stock, 'daily return')] = merged_portfolio[(stock, 'close')].pct_change()\n",
    "\n",
    "# Then we sort the columns to show within each stock\n",
    "merged_portfolio = merged_portfolio.sort_index(axis=1, level=0)\n",
    "\n",
    "#Display first and last five rows of the portfolio \n",
    "display(merged_portfolio.head())\n",
    "display(merged_portfolio.tail())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a Stock Volatility column that will calculate the standard deviation of the closing stock prices\n",
    "\n",
    "# Since there are multiple columns with the name close, we must create a loop \n",
    "\n",
    "for volatility in merged_portfolio.columns.levels[0]:\n",
    "    merged_portfolio.loc[:,(volatility, 'stock volatility')] = merged_portfolio[(volatility, 'close')].pct_change().rolling(window=200).std()\n",
    "\n",
    "# Then we sort the columns to show within each stock\n",
    "merged_portfolio = merged_portfolio.sort_index(axis=1, level=0)\n",
    "\n",
    "#Display portfolio \n",
    "merged_portfolio.tail(10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Graph your stock volatility over the course of the last year by using the data you calculated above\n",
    "# We are graphing the data to get a visualization over the stock volatility over the last year\n",
    "\n",
    "# First remove the close, volume, lagged volume, and daily return columns from the portfolio to just plot the volume\n",
    "\n",
    "merged_portfolio_stock_volatility = merged_portfolio.drop(['close', 'volume', 'lagged volume', 'daily return'], axis=1, level=1)\n",
    "\n",
    "merged_portfolio_stock_volatility.plot()\n",
    "plt.title('Stock Volatility for Chosen Stocks')\n",
    "plt.ylabel('Volatility')\n",
    "plt.xlabel('Date')\n",
    "plt.legend(loc=\"lower right\", bbox_to_anchor=(1.53, -0.19), ncol=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Creating a correlation table of the daily stock return, lagged volume, and stock volatility\n",
    "\n",
    "merged_portfolio_corr = merged_portfolio.drop(['close', 'volume'], axis=1, level=1)\n",
    "\n",
    "merged_portfolio_corr.corr()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Original idea to calculate correlation \n",
    "\n",
    "# merged_portfolio_TSM_corr = merged_portfolio.drop([\"QCOM\", \"VALE\", \"AMD\", \"BHP\", \"RIO\", \"FCX\", \"INTC\", \"MSFT\", \"DDD\", \"NVDA\", \"TSLA\", \"AMAT\", \"F\", \"VOO\"], axis=1, level=0)\n",
    "\n",
    "# merged_portfolio_TSM_corr.corr()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# <font color=LightSalmon>Create Bollinger Bands to Determine Return Percentage</font>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "merged_portfolio_daily_returns = merged_portfolio.drop(['close', 'volume', 'lagged volume', 'stock volatility'], axis=1, level=1)\n",
    "\n",
    "merged_portfolio_daily_returns.dropna(inplace=True)\n",
    "\n",
    "merged_portfolio_daily_returns.head(10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Original strategy to get the covariance of each stock in portfolio\n",
    "\n",
    "# Below calculates the covariance of TSM to the VOO\n",
    "\n",
    "merged_portfolio_TSM_cov = merged_portfolio_daily_returns['TSM']['daily return'].cov(merged_portfolio_daily_returns['VOO']['daily return'])\n",
    "\n",
    "merged_portfolio_TSM_cov\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Creating a loop to get all the stock covariances to the VOO at once in the order below\n",
    "\n",
    "stock_ticker_list = [\"TSM\", \"QCOM\", \"VALE\", \"AMD\", \"BHP\", \"RIO\", \"FCX\", \"INTC\", \"MSFT\", \"DDD\", \"NVDA\", \"TSLA\", \"AMAT\", \"F\"]\n",
    "\n",
    "stock_covariance_list = []\n",
    "\n",
    "for stock in stock_ticker_list:\n",
    "    stockcov = merged_portfolio_daily_returns[stock]['daily return'].cov(merged_portfolio_daily_returns['VOO']['daily return'])\n",
    "    stock_covariance_list+=[stockcov]\n",
    "\n",
    "print(stock_covariance_list)\n",
    "   "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create the variance calculation of all the daily returns vs. VOO\n",
    "\n",
    "VOO_variance = merged_portfolio_daily_returns['VOO']['daily return'].var()\n",
    "\n",
    "print(VOO_variance)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# trying to create a loop that divided the covariance of each stock by the variance of VOO, both of which have been calculated above already\n",
    "\n",
    "stock_beta_list = []\n",
    "\n",
    "for covariance in stock_covariance_list:\n",
    "    stockbeta = covariance / VOO_variance\n",
    "    stock_beta_list += [stockbeta]\n",
    "\n",
    "print(stock_beta_list)\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Remove VOO from the stock_beta_list\n",
    "# Assign the VOO beta to a variable\n",
    "voo_beta = stock_beta_list.pop()\n",
    "\n",
    "# Print the beta of VOO\n",
    "print(voo_beta)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Assign the stock_beta_list without voo to stock_beta_list_wo_voo\n",
    "stock_beta_list_wo_voo = stock_beta_list\n",
    "\n",
    "# Print stock_beta_list_wo_voo\n",
    "print(stock_beta_list_wo_voo)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# If we used even weights for all stocks in the portfolio\n",
    "# The portfolio beta would be the sum of the betas for all the stocks over the number of stocks in the portfolio\n",
    "# Calculating the portfolio beta\n",
    "stock_beta_list_wo_voo_sum = sum(stock_beta_list_wo_voo)\n",
    "stock_beta_list_wo_voo_count = len(stock_beta_list_wo_voo)\n",
    "stock_beta_list_wo_voo_beta = stock_beta_list_wo_voo_sum / stock_beta_list_wo_voo_count\n",
    "\n",
    "# Print the portfolio beta given even weights for all stocks\n",
    "print(stock_beta_list_wo_voo_beta)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a new DataFrame trading_df using the merged_portfolio DataFrame\n",
    "trading_df = merged_portfolio\n",
    "\n",
    "# Display the first five rows of the DataFrame\n",
    "trading_df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Display Column headers for the trading_df\n",
    "display(list(trading_df.columns.values))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Drop VOO from the trading_df DataFRame\n",
    "trading_df = trading_df.drop(['VOO'], axis=1)\n",
    "\n",
    "# View the Updated DataFrame Columns\n",
    "display(list(trading_df.columns.values))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# View the Updated DataFrame\n",
    "display(trading_df.head())\n",
    "display(trading_df.tail())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Define a window size of 4\n",
    "short_window = 4\n",
    "\n",
    "# Define a window size of 100\n",
    "long_window = 100\n",
    "\n",
    "# Re-define stock_ticker_list to ensure integrity\n",
    "stock_ticker_list = [\"AMAT\", \"AMD\", \"BHP\", \"DDD\", \"F\", \"FCX\", \"INTC\", \"MSFT\", \"NVDA\", \"QCOM\", \"RIO\", \"TSLA\", \"TSM\", \"VALE\"]\n",
    "\n",
    "# Loop through the trading_df to create the sma_fast and sma_slow columns \n",
    "for stock in stock_ticker_list:\n",
    "    # Create an SMA that uses short_window, and assign it to a new column named “sma_fast”\n",
    "    trading_df.loc[:,(stock, 'sma_fast')] = trading_df[(stock, 'close')].rolling(window=short_window).mean()\n",
    "    # Create an SMA that uses long_window, and assign it to a new column named “sma_slow”\n",
    "    trading_df.loc[:,(stock, 'sma_slow')] = trading_df[(stock, 'close')].rolling(window=long_window).mean()\n",
    "    \n",
    "# Then we sort the columns to show within each stock\n",
    "trading_df = trading_df.sort_index(axis=1, level=0)\n",
    "    \n",
    "# Display the first and last five rows of the trading_df\n",
    "display(trading_df.head())\n",
    "display(trading_df.tail())\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Drop the NaNs using dropna()\n",
    "trading_df.dropna(axis=0, inplace=True)\n",
    "\n",
    "# Display the first and last five rows\n",
    "display(trading_df.head())\n",
    "display(trading_df.tail())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <font color=MediumSlateBlue>Create Training Datasets</font>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create X DataFrame\n",
    "X = pd.DataFrame(columns = trading_df.columns)\n",
    "\n",
    "# Re-define stock_ticker_list to ensure integrity\n",
    "stock_ticker_list = [\"AMAT\", \"AMD\", \"BHP\", \"DDD\", \"F\", \"FCX\", \"INTC\", \"MSFT\", \"NVDA\", \"QCOM\", \"RIO\", \"TSLA\", \"TSM\", \"VALE\"]\n",
    "\n",
    "# Assign a copy of the `sma_fast` and `sma_slow` columns to the new DataFrame called `X`\n",
    "# Loop through the trading_df\n",
    "for stock in stock_ticker_list:\n",
    "    X.loc[:,(stock, 'sma_fast')] = trading_df[(stock, 'sma_fast')].shift().dropna().copy()\n",
    "    X.loc[:,(stock, 'sma_slow')] = trading_df[(stock, 'sma_slow')].shift().dropna().copy()\n",
    "\n",
    "# Drop columns other than sma_fast and sma_slow\n",
    "X = X.drop(['close', 'daily return', 'lagged volume', 'stock volatility', 'volume'], axis='columns', level=1)\n",
    "\n",
    "# Display the first and last five rows of the X DataFrame\n",
    "display(X.head())\n",
    "display(X.tail())\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Re-define stock_ticker_list to ensure integrity\n",
    "stock_ticker_list = [\"AMAT\", \"AMD\", \"BHP\", \"DDD\", \"F\", \"FCX\", \"INTC\", \"MSFT\", \"NVDA\", \"QCOM\", \"RIO\", \"TSLA\", \"TSM\", \"VALE\"]\n",
    "\n",
    "# Create a new column in the `trading_df` called \"signal\" setting its value to zero.\n",
    "# Loop through the trading_df to create the signal column\n",
    "for stock in stock_ticker_list:\n",
    "    trading_df.loc[:,(stock, 'signal')] = 0.0\n",
    "\n",
    "# Then we sort the columns to show within each stock\n",
    "trading_df = trading_df.sort_index(axis=1, level=0)\n",
    "\n",
    "# Review the trading_df\n",
    "# Display the first and last five rows\n",
    "display(trading_df.head())\n",
    "display(trading_df.tail())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Set signal values\n",
    "for stock in stock_ticker_list:\n",
    "    # Create the signal to buy\n",
    "    trading_df.loc[(trading_df[stock]['daily return'] >= 0), (stock, 'signal')] = 1\n",
    "    # Create the signal to sell\n",
    "    trading_df.loc[(trading_df[stock]['daily return'] < 0), (stock, 'signal')] = -1\n",
    "\n",
    "# Review the trading_df\n",
    "# Display the first and last five rows\n",
    "display(trading_df.head())\n",
    "display(trading_df.tail())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Copy the new \"signal\" column to a new Series called `y`.\n",
    "\n",
    "# Create y DataFrame\n",
    "y = pd.DataFrame(columns = trading_df.columns)\n",
    "\n",
    "# Re-define stock_ticker_list to ensure integrity\n",
    "stock_ticker_list = [\"AMAT\", \"AMD\", \"BHP\", \"DDD\", \"F\", \"FCX\", \"INTC\", \"MSFT\", \"NVDA\", \"QCOM\", \"RIO\", \"TSLA\", \"TSM\", \"VALE\"]\n",
    "\n",
    "# Assign a copy of the `signal` column to the new DataFrame called `y`\n",
    "# Loop through the trading_df\n",
    "for stock in stock_ticker_list:\n",
    "    y.loc[:,(stock, 'signal')] = trading_df[(stock, 'signal')].copy()\n",
    "\n",
    "# Drop columns other than signal\n",
    "y = y.drop(['close', 'daily return', 'lagged volume', 'sma_fast', 'sma_slow', 'stock volatility', 'volume'], axis='columns', level=1)\n",
    "\n",
    "# Display the first and last five rows of the y DataFrame\n",
    "display(y.head())\n",
    "display(y.tail())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Select the start of the training period\n",
    "training_begin = X.index.min()\n",
    "\n",
    "# Display the training begin date\n",
    "print(training_begin)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Select the ending period for the training data with an offset of 1 month\n",
    "training_end = X.index.min() + DateOffset(months=1)\n",
    "\n",
    "# Display the training end date\n",
    "print(training_end)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Generate the X_train and y_train DataFrames\n",
    "X_train = X.loc[training_begin:training_end]\n",
    "y_train = y.loc[training_begin:training_end]\n",
    "\n",
    "# Display sample data for X_train\n",
    "display(X_train.head(2))\n",
    "display(X_train.tail(2))\n",
    "\n",
    "# Display sample data for y_train\n",
    "display(y_train.head(2))\n",
    "display(y_train.tail(2))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Generate the Testing End\n",
    "testing_end = training_end + DateOffset(months=1)\n",
    "\n",
    "# Display the testing_end\n",
    "print(testing_end)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Generate the X_test and y_test DataFrames\n",
    "testing_end = training_end + DateOffset(months=1)\n",
    "X_test = X.loc[training_end:testing_end]\n",
    "y_test = y.loc[training_end:testing_end]\n",
    "\n",
    "# Display sample data for X_test\n",
    "display(X_test.head(2))\n",
    "display(X_test.tail(2))\n",
    "\n",
    "# Display sample data for y_test\n",
    "display(y_test.head(2))\n",
    "display(y_test.tail(2))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Stocks in Data Set are \"AMAT\", \"AMD\", \"BHP\", \"DDD\", \"F\", \"FCX\", \"INTC\", \"MSFT\", \"NVDA\", \"QCOM\", \"RIO\", \"TSLA\", \"TSM\", \"VALE\"\n",
    "\n",
    "# Create a StandardScaler instance\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# Apply the scaler model to fit the X_train data\n",
    "# X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Transform the X_train and X_test DataFrames using the X_scaler\n",
    "# X_train_scaled = X_scaler.transform(X_train)\n",
    "# X_test_scaled = X_scaler.transform(X_test)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create the classifier model\n",
    "# svm_model = svm.SVC()\n",
    "\n",
    "# Fit the model to the data using X_train_scaled and y_train\n",
    "# svm_model = svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Use the trained model to predict the trading signals for the training data\n",
    "# training_signal_predictions = svm_model.predict(X_train_scaled)\n",
    "\n",
    "# Display the sample predictions\n",
    "# training_signal_predictions"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Evaluate the model using a classification report\n",
    "# training_report = classification_report(y_train, training_signal_predictions)\n",
    "# print(training_report)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Stocks in Data Set are \"AMAT\", \"AMD\", \"BHP\", \"DDD\", \"F\", \"FCX\", \"INTC\", \"MSFT\", \"NVDA\", \"QCOM\", \"RIO\", \"TSLA\", \"TSM\", \"VALE\"\n",
    "\n",
    "# Create StandardScaler instances\n",
    "scaler_AMAT = StandardScaler()\n",
    "scaler_AMD = StandardScaler()\n",
    "scaler_BHP = StandardScaler()\n",
    "scaler_DDD = StandardScaler()\n",
    "scaler_F = StandardScaler()\n",
    "scaler_FCX = StandardScaler()\n",
    "scaler_INTC = StandardScaler()\n",
    "scaler_MSFT = StandardScaler()\n",
    "scaler_NVDA = StandardScaler()\n",
    "scaler_QCOM = StandardScaler()\n",
    "scaler_RIO = StandardScaler()\n",
    "scaler_TSLA = StandardScaler()\n",
    "scaler_TSM = StandardScaler()\n",
    "scaler_VALE = StandardScaler()\n",
    "\n",
    "# Apply the scaler model to fit the X_train data\n",
    "X_scaler_AMAT = scaler_AMAT.fit(X_train['AMAT'])\n",
    "X_scaler_AMD = scaler_AMD.fit(X_train['AMD'])\n",
    "X_scaler_BHP = scaler_BHP.fit(X_train['BHP'])\n",
    "X_scaler_DDD = scaler_DDD.fit(X_train['DDD'])\n",
    "X_scaler_F = scaler_F.fit(X_train['F'])\n",
    "X_scaler_FCX = scaler_FCX.fit(X_train['FCX'])\n",
    "X_scaler_INTC = scaler_INTC.fit(X_train['INTC'])\n",
    "X_scaler_MSFT = scaler_MSFT.fit(X_train['MSFT'])\n",
    "X_scaler_NVDA = scaler_NVDA.fit(X_train['NVDA'])\n",
    "X_scaler_QCOM = scaler_QCOM.fit(X_train['QCOM'])\n",
    "X_scaler_RIO = scaler_RIO.fit(X_train['RIO'])\n",
    "X_scaler_TSLA = scaler_TSLA.fit(X_train['TSLA'])\n",
    "X_scaler_TSM = scaler_TSM.fit(X_train['TSM'])\n",
    "X_scaler_VALE = scaler_VALE.fit(X_train['VALE'])\n",
    "\n",
    "# Transform the X_train and X_test DataFrames using the X_scaler\n",
    "X_train_AMAT_scaled = X_scaler_AMAT.transform(X_train['AMAT'])\n",
    "X_test_AMAT_scaled = X_scaler_AMAT.transform(X_test['AMAT'])\n",
    "\n",
    "X_train_AMD_scaled = X_scaler_AMD.transform(X_train['AMD'])\n",
    "X_test_AMD_scaled = X_scaler_AMD.transform(X_test['AMD'])\n",
    "\n",
    "X_train_BHP_scaled = X_scaler_BHP.transform(X_train['BHP'])\n",
    "X_test_BHP_scaled = X_scaler_BHP.transform(X_test['BHP'])\n",
    "\n",
    "X_train_DDD_scaled = X_scaler_DDD.transform(X_train['DDD'])\n",
    "X_test_DDD_scaled = X_scaler_DDD.transform(X_test['DDD'])\n",
    "\n",
    "X_train_F_scaled = X_scaler_F.transform(X_train['F'])\n",
    "X_test_F_scaled = X_scaler_F.transform(X_test['F'])\n",
    "\n",
    "X_train_FCX_scaled = X_scaler_FCX.transform(X_train['FCX'])\n",
    "X_test_FCX_scaled = X_scaler_FCX.transform(X_test['FCX'])\n",
    "\n",
    "X_train_INTC_scaled = X_scaler_INTC.transform(X_train['INTC'])\n",
    "X_test_INTC_scaled = X_scaler_INTC.transform(X_test['INTC'])\n",
    "\n",
    "X_train_MSFT_scaled = X_scaler_MSFT.transform(X_train['MSFT'])\n",
    "X_test_MSFT_scaled = X_scaler_MSFT.transform(X_test['MSFT'])\n",
    "\n",
    "X_train_NVDA_scaled = X_scaler_NVDA.transform(X_train['NVDA'])\n",
    "X_test_NVDA_scaled = X_scaler_NVDA.transform(X_test['NVDA'])\n",
    "\n",
    "X_train_QCOM_scaled = X_scaler_QCOM.transform(X_train['QCOM'])\n",
    "X_test_QCOM_scaled = X_scaler_QCOM.transform(X_test['QCOM'])\n",
    "\n",
    "X_train_RIO_scaled = X_scaler_RIO.transform(X_train['RIO'])\n",
    "X_test_RIO_scaled = X_scaler_RIO.transform(X_test['RIO'])\n",
    "\n",
    "X_train_TSLA_scaled = X_scaler_TSLA.transform(X_train['TSLA'])\n",
    "X_test_TSLA_scaled = X_scaler_TSLA.transform(X_test['TSLA'])\n",
    "\n",
    "X_train_TSM_scaled = X_scaler_TSM.transform(X_train['TSM'])\n",
    "X_test_TSM_scaled = X_scaler_TSM.transform(X_test['TSM'])\n",
    "\n",
    "X_train_VALE_scaled = X_scaler_VALE.transform(X_train['VALE'])\n",
    "X_test_VALE_scaled = X_scaler_VALE.transform(X_test['VALE'])\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Stocks in Data Set are \"AMAT\", \"AMD\", \"BHP\", \"DDD\", \"F\", \"FCX\", \"INTC\", \"MSFT\", \"NVDA\", \"QCOM\", \"RIO\", \"TSLA\", \"TSM\", \"VALE\"\n",
    "\n",
    "# Create the classifier model\n",
    "svm_model_1 = svm.SVC()\n",
    "svm_model_2 = svm.SVC()\n",
    "svm_model_3 = svm.SVC()\n",
    "svm_model_4 = svm.SVC()\n",
    "svm_model_5 = svm.SVC()\n",
    "svm_model_6 = svm.SVC()\n",
    "svm_model_7 = svm.SVC()\n",
    "svm_model_8 = svm.SVC()\n",
    "svm_model_9 = svm.SVC()\n",
    "svm_model_10 = svm.SVC()\n",
    "svm_model_11 = svm.SVC()\n",
    "svm_model_12 = svm.SVC()\n",
    "svm_model_13 = svm.SVC()\n",
    "svm_model_14 = svm.SVC()\n",
    "\n",
    "# Fit the model to the data using X_train_scaled and y_train\n",
    "svm_model_AMAT = svm_model_1.fit(X_train_AMAT_scaled, y_train['AMAT'])\n",
    "svm_model_AMD = svm_model_2.fit(X_train_AMD_scaled, y_train['AMD'])\n",
    "svm_model_BHP = svm_model_3.fit(X_train_BHP_scaled, y_train['BHP'])\n",
    "svm_model_DDD = svm_model_4.fit(X_train_DDD_scaled, y_train['DDD'])\n",
    "svm_model_F = svm_model_5.fit(X_train_F_scaled, y_train['F'])\n",
    "svm_model_FCX = svm_model_6.fit(X_train_FCX_scaled, y_train['FCX'])\n",
    "svm_model_INTC = svm_model_7.fit(X_train_INTC_scaled, y_train['INTC'])\n",
    "svm_model_MSFT = svm_model_8.fit(X_train_MSFT_scaled, y_train['MSFT'])\n",
    "svm_model_NVDA = svm_model_9.fit(X_train_NVDA_scaled, y_train['NVDA'])\n",
    "svm_model_QCOM = svm_model_10.fit(X_train_QCOM_scaled, y_train['QCOM'])\n",
    "svm_model_RIO = svm_model_11.fit(X_train_RIO_scaled, y_train['RIO'])\n",
    "svm_model_TSLA = svm_model_12.fit(X_train_TSLA_scaled, y_train['TSLA'])\n",
    "svm_model_TSM = svm_model_13.fit(X_train_TSM_scaled, y_train['TSM'])\n",
    "svm_model_VALE = svm_model_14.fit(X_train_VALE_scaled, y_train['VALE'])\n",
    "\n",
    "# Use the trained model to predict the trading signals for the training data\n",
    "training_signal_predictions_AMAT = svm_model_AMAT.predict(X_train_AMAT_scaled)\n",
    "training_signal_predictions_AMD = svm_model_AMD.predict(X_train_AMD_scaled)\n",
    "training_signal_predictions_BHP = svm_model_BHP.predict(X_train_BHP_scaled)\n",
    "training_signal_predictions_DDD = svm_model_DDD.predict(X_train_DDD_scaled)\n",
    "training_signal_predictions_F = svm_model_F.predict(X_train_F_scaled)\n",
    "training_signal_predictions_FCX = svm_model_FCX.predict(X_train_FCX_scaled)\n",
    "training_signal_predictions_INTC = svm_model_INTC.predict(X_train_INTC_scaled)\n",
    "training_signal_predictions_MSFT = svm_model_MSFT.predict(X_train_MSFT_scaled)\n",
    "training_signal_predictions_NVDA = svm_model_NVDA.predict(X_train_NVDA_scaled)\n",
    "training_signal_predictions_QCOM = svm_model_QCOM.predict(X_train_QCOM_scaled)\n",
    "training_signal_predictions_RIO = svm_model_RIO.predict(X_train_RIO_scaled)\n",
    "training_signal_predictions_TSLA = svm_model_TSLA.predict(X_train_TSLA_scaled)\n",
    "training_signal_predictions_TSM = svm_model_TSM.predict(X_train_TSM_scaled)\n",
    "training_signal_predictions_VALE = svm_model_VALE.predict(X_train_VALE_scaled)\n",
    "\n",
    "# Display the sample predictions for AMAT\n",
    "training_signal_predictions_AMAT[:10]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Stocks in Data Set are \"AMAT\", \"AMD\", \"BHP\", \"DDD\", \"F\", \"FCX\", \"INTC\", \"MSFT\", \"NVDA\", \"QCOM\", \"RIO\", \"TSLA\", \"TSM\", \"VALE\"\n",
    "\n",
    "# Evaluate the model using a classification report for each of the stocks\n",
    "training_report_AMAT = classification_report(y_train['AMAT'], training_signal_predictions_AMAT)\n",
    "training_report_AMD = classification_report(y_train['AMD'], training_signal_predictions_AMD)\n",
    "training_report_BHP = classification_report(y_train['BHP'], training_signal_predictions_BHP)\n",
    "training_report_DDD = classification_report(y_train['DDD'], training_signal_predictions_DDD)\n",
    "training_report_F = classification_report(y_train['F'], training_signal_predictions_F)\n",
    "training_report_FCX = classification_report(y_train['FCX'], training_signal_predictions_FCX)\n",
    "training_report_INTC = classification_report(y_train['INTC'], training_signal_predictions_INTC)\n",
    "training_report_MSFT = classification_report(y_train['MSFT'], training_signal_predictions_MSFT)\n",
    "training_report_NVDA = classification_report(y_train['NVDA'], training_signal_predictions_NVDA)\n",
    "training_report_QCOM = classification_report(y_train['QCOM'], training_signal_predictions_QCOM)\n",
    "training_report_RIO = classification_report(y_train['RIO'], training_signal_predictions_RIO)\n",
    "training_report_TSLA = classification_report(y_train['TSLA'], training_signal_predictions_TSLA)\n",
    "training_report_TSM = classification_report(y_train['TSM'], training_signal_predictions_TSM)\n",
    "training_report_VALE = classification_report(y_train['VALE'], training_signal_predictions_VALE)\n",
    "\n",
    "# Display the Classification Reports\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"AMAT Training Report\")\n",
    "print(training_report_AMAT)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"AMD Training Report\")\n",
    "print(training_report_AMD)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"BHP Training Report\")\n",
    "print(training_report_BHP)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"DDD Training Report\")\n",
    "print(training_report_DDD)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"F Training Report\")\n",
    "print(training_report_F)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"FCX Training Report\")\n",
    "print(training_report_FCX)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"INTC Training Report\")\n",
    "print(training_report_INTC)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"MSFT Training Report\")\n",
    "print(training_report_MSFT)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"NVDA Training Report\")\n",
    "print(training_report_NVDA)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"QCOM Training Report\")\n",
    "print(training_report_QCOM)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"RIO Training Report\")\n",
    "print(training_report_RIO)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"TSLA Training Report\")\n",
    "print(training_report_TSLA)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"TSM Training Report\")\n",
    "print(training_report_TSM)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"VALE Training Report\")\n",
    "print(training_report_VALE)\n",
    "\n",
    "print(\"----------------------------\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <font color=MediumSlateBlue>Backtesting</font>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Stocks in Data Set are \"AMAT\", \"AMD\", \"BHP\", \"DDD\", \"F\", \"FCX\", \"INTC\", \"MSFT\", \"NVDA\", \"QCOM\", \"RIO\", \"TSLA\", \"TSM\", \"VALE\"\n",
    "\n",
    "# Use the trained models to predict the trading signals for the testing data.\n",
    "testing_signal_predictions_AMAT = svm_model_AMAT.predict(X_test_AMAT_scaled)\n",
    "testing_signal_predictions_AMD = svm_model_AMD.predict(X_test_AMD_scaled)\n",
    "testing_signal_predictions_BHP = svm_model_BHP.predict(X_test_BHP_scaled)\n",
    "testing_signal_predictions_DDD = svm_model_DDD.predict(X_test_DDD_scaled)\n",
    "testing_signal_predictions_F = svm_model_F.predict(X_test_F_scaled)\n",
    "testing_signal_predictions_FCX = svm_model_FCX.predict(X_test_FCX_scaled)\n",
    "testing_signal_predictions_INTC = svm_model_INTC.predict(X_test_INTC_scaled)\n",
    "testing_signal_predictions_MSFT = svm_model_MSFT.predict(X_test_MSFT_scaled)\n",
    "testing_signal_predictions_NVDA = svm_model_NVDA.predict(X_test_NVDA_scaled)\n",
    "testing_signal_predictions_QCOM = svm_model_QCOM.predict(X_test_QCOM_scaled)\n",
    "testing_signal_predictions_RIO = svm_model_RIO.predict(X_test_RIO_scaled)\n",
    "testing_signal_predictions_TSLA = svm_model_TSLA.predict(X_test_TSLA_scaled)\n",
    "testing_signal_predictions_TSM = svm_model_TSM.predict(X_test_TSM_scaled)\n",
    "testing_signal_predictions_VALE = svm_model_VALE.predict(X_test_VALE_scaled)\n",
    "\n",
    "# Evaluate the model's ability to predict the trading signal for the testing data\n",
    "testing_report_AMAT = classification_report(y_test['AMAT'], testing_signal_predictions_AMAT)\n",
    "testing_report_AMD = classification_report(y_test['AMD'], testing_signal_predictions_AMD)\n",
    "testing_report_BHP = classification_report(y_test['BHP'], testing_signal_predictions_BHP)\n",
    "testing_report_DDD = classification_report(y_test['DDD'], testing_signal_predictions_DDD)\n",
    "testing_report_F = classification_report(y_test['F'], testing_signal_predictions_F)\n",
    "testing_report_FCX = classification_report(y_test['FCX'], testing_signal_predictions_FCX)\n",
    "testing_report_INTC = classification_report(y_test['INTC'], testing_signal_predictions_INTC)\n",
    "testing_report_MSFT = classification_report(y_test['MSFT'], testing_signal_predictions_MSFT)\n",
    "testing_report_NVDA = classification_report(y_test['NVDA'], testing_signal_predictions_NVDA)\n",
    "testing_report_QCOM = classification_report(y_test['QCOM'], testing_signal_predictions_QCOM)\n",
    "testing_report_RIO = classification_report(y_test['RIO'], testing_signal_predictions_RIO)\n",
    "testing_report_TSLA = classification_report(y_test['TSLA'], testing_signal_predictions_TSLA)\n",
    "testing_report_TSM = classification_report(y_test['TSM'], testing_signal_predictions_TSM)\n",
    "testing_report_VALE = classification_report(y_test['VALE'], testing_signal_predictions_VALE)\n",
    "\n",
    "# Display the Classification Reports\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"AMAT Testing Report\")\n",
    "print(testing_report_AMAT)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"AMD Testing Report\")\n",
    "print(testing_report_AMD)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"BHP Testing Report\")\n",
    "print(testing_report_BHP)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"DDD Testing Report\")\n",
    "print(testing_report_DDD)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"F Testing Report\")\n",
    "print(testing_report_F)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"FCX Testing Report\")\n",
    "print(testing_report_FCX)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"INTC Testing Report\")\n",
    "print(testing_report_INTC)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"MSFT Testing Report\")\n",
    "print(testing_report_MSFT)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"NVDA Testing Report\")\n",
    "print(testing_report_NVDA)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"QCOM Testing Report\")\n",
    "print(testing_report_QCOM)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"RIO Testing Report\")\n",
    "print(testing_report_RIO)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"TSLA Testing Report\")\n",
    "print(testing_report_TSLA)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"TSM Testing Report\")\n",
    "print(testing_report_TSM)\n",
    "\n",
    "print(\"----------------------------\")\n",
    "\n",
    "print(\"VALE Testing Report\")\n",
    "print(testing_report_VALE)\n",
    "\n",
    "print(\"----------------------------\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('algo': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "83ff2463df67d4299958bd5f4082f8634e97706bb1a9308762362deea05bac91"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}